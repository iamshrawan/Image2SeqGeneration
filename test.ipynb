{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.autograd.variable import Variable\n",
    "from typing import List\n",
    "from PIL import Image\n",
    "from torchvision import transforms, models\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, in_channels=3, dropout=0.2):\n",
    "        \"\"\"\n",
    "        Encoder for Image2NodeNet.\n",
    "        :param dropout: dropout\n",
    "        \"\"\"\n",
    "        super(Encoder, self).__init__()\n",
    "        self.p = dropout\n",
    "        self.conv1 = nn.Conv2d(in_channels, 8, 3, padding=(1, 1))\n",
    "        self.conv2 = nn.Conv2d(8, 16, 3, padding=(1, 1))\n",
    "        self.conv3 = nn.Conv2d(16, 32, 3, padding=(1, 1))\n",
    "        self.conv4 = nn.Conv2d(32, 64, 3, padding=(1,1))\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(self.drop(F.relu(self.conv1(x))), (2, 2))\n",
    "        x = F.max_pool2d(self.drop(F.relu(self.conv2(x))), (2, 2))\n",
    "        x = F.max_pool2d(self.drop(F.relu(self.conv3(x))), (2, 2))\n",
    "        x = F.max_pool2d(F.relu(self.conv4(x)), (2, 2))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResnetEncoder(nn.Module):\n",
    "    def __init__(self, arch_name, in_channels=3, pretrained=False):\n",
    "        super(ResnetEncoder, self).__init__()\n",
    "        self.arch_name = arch_name\n",
    "        self.pretrained = pretrained\n",
    "        self.in_channels = in_channels\n",
    "        self.build_model()\n",
    "\n",
    "    def build_model(self):\n",
    "        print(f'Building {self.arch_name} model (pretrained={self.pretrained})!!')\n",
    "                    \n",
    "        if self.arch_name == 'resnet50':\n",
    "            base_model = models.resnet50(pretrained=self.pretrained)\n",
    "            self.features = nn.Sequential(*list(base_model.children())[:-1])\n",
    "\n",
    "        elif self.arch_name == 'resnet18':\n",
    "            base_model = models.resnet18(pretrained=self.pretrained)\n",
    "            self.features = nn.Sequential(*list(base_model.children())[:-1]) \n",
    "                \n",
    "        else:\n",
    "            raise('This architecture is not supported!!')\n",
    "        \n",
    "        if self.in_channels != 3:\n",
    "            self.features[0] =  nn.Conv2d(self.in_channels, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "        if self.pretrained:\n",
    "            i = 4 if self.in_channel != 3 else 0\n",
    "            # Freeze all weights before CB4\n",
    "            for param in self.features[i:6].parameters():\n",
    "                param.requires_grad = False\n",
    "                                        \n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.features(x)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 256, 256])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im = Image.open('data/tables/Table_1/Table_1_Image_10.png').convert('RGB')\n",
    "im_t = transforms.functional.to_tensor(transforms.functional.center_crop(im, 256)).unsqueeze(0)\n",
    "im_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building resnet18 model (pretrained=False)!!\n"
     ]
    }
   ],
   "source": [
    "enc = ResnetEncoder(arch_name='resnet18')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /tmp/pip-req-build-gqmopi53/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512, 1, 1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded = enc(im_t)\n",
    "encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Image2NodeNet(nn.Module):\n",
    "    def __init__(self,\n",
    "                 hd_sz,\n",
    "                 input_size,\n",
    "                 inp_op_sz,\n",
    "                 encoder,\n",
    "                 num_layers=1,\n",
    "                 time_steps=3,\n",
    "                 dropout=0.5):\n",
    "        \"\"\"\n",
    "        Defines RNN structure that takes features encoded by CNN and produces program\n",
    "        instructions at every time step.\n",
    "        :inp_op_sz: total number of unique operations\n",
    "        :param dropout: dropout\n",
    "        :param hd_sz: rnn hidden size\n",
    "        :param input_size: input_size (CNN feature size) to rnn\n",
    "        :param encoder: Feature extractor network object\n",
    "        :param num_layers: Number of layers to rnn\n",
    "        :param time_steps: max length of program\n",
    "        \"\"\"\n",
    "        super(Image2NodeNet, self).__init__()\n",
    "        self.hd_sz = hd_sz\n",
    "        self.in_sz = input_size\n",
    "        self.input_op_sz = inp_op_sz\n",
    "        self.num_layers = num_layers\n",
    "        self.encoder = encoder\n",
    "        self.time_steps = time_steps\n",
    "\n",
    "        self.rnn = nn.GRU(\n",
    "            input_size=self.in_sz + self.input_op_sz,\n",
    "            hidden_size=self.hd_sz,\n",
    "            num_layers=self.num_layers,\n",
    "            batch_first=False)\n",
    "\n",
    "\n",
    "        self.logsoftmax = nn.LogSoftmax(1)\n",
    "        self.softmax = nn.Softmax(1)\n",
    "\n",
    "        self.dense_fc_1 = nn.Linear(\n",
    "            in_features=self.hd_sz, out_features=self.hd_sz)\n",
    "        self.dense_output = nn.Linear(\n",
    "            in_features=self.hd_sz, out_features=(self.input_op_sz))\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x: List):\n",
    " \n",
    "        data, input_op, program_len = x\n",
    "\n",
    "        #assert data.size()[0] == program_len + 1, \"Incorrect stack size!!\"\n",
    "        batch_size = data.size()[0]\n",
    "        h = Variable(torch.zeros(self.num_layers, batch_size, self.hd_sz))\n",
    "        x_f = self.encoder(data)\n",
    "        x_f = x_f.view(1, batch_size, self.in_sz)\n",
    "        outputs = []\n",
    "        for timestep in range(0, program_len + 1):\n",
    "            # X_f is always input to the RNN at every time step\n",
    "            # along with previous predicted label\n",
    "            input_op_rnn = input_op[:, timestep, :]\n",
    "            input_op_rnn = input_op_rnn.view(1, batch_size,\n",
    "                                                self.input_op_sz)\n",
    "            input = torch.cat((self.drop(x_f), input_op_rnn), 2)\n",
    "            print(input.shape)\n",
    "            out, h = self.rnn(input, h)\n",
    "            hd = self.relu(self.dense_fc_1(self.drop(out[0])))\n",
    "            output = self.logsoftmax(self.dense_output(self.drop(hd)))\n",
    "            outputs.append(output)\n",
    "        return outputs\n",
    "    \n",
    "    def test(self, x: List):\n",
    " \n",
    "        data, input_op, program_len = x\n",
    "\n",
    "        batch_size = data.size()[0]\n",
    "        h = Variable(torch.zeros(self.num_layers, batch_size, self.hd_sz))\n",
    "        x_f = self.encoder(data)\n",
    "        x_f = x_f.view(1, batch_size, self.in_sz)\n",
    "        last_output = input_op[:,0,:]\n",
    "        outputs = []\n",
    "        for timestep in range(0, program_len + 1):\n",
    "            input_op_rnn = last_output.view(1, batch_size,\n",
    "                                                self.input_op_sz)\n",
    "            input = torch.cat((self.drop(x_f), input_op_rnn), 2)\n",
    "            out, h = self.rnn(input, h)\n",
    "            hd = self.relu(self.dense_fc_1(self.drop(out[0])))\n",
    "            output = self.logsoftmax(self.dense_output(self.drop(hd)))\n",
    "            next_input_op = torch.max(output, 1)[1].view(batch_size, 1)\n",
    "            arr = Variable(\n",
    "                    torch.zeros(batch_size, self.input_op_sz).scatter_(\n",
    "                        1, next_input_op.data.cpu(), 1.0)).cuda()\n",
    "\n",
    "            last_output = arr\n",
    "            outputs.append(output)\n",
    "        return outputs\n",
    "\n",
    "    def beam_search(self, data: List, w: int, max_time: int):\n",
    "        \"\"\"\n",
    "        Implements beam search for different models.\n",
    "        :param data: Input data\n",
    "        :param w: beam width\n",
    "        :param max_time: Maximum length till the program has to be generated\n",
    "        :return all_beams: all beams to find out the indices of all the\n",
    "        \"\"\"\n",
    "        data, input_op = data\n",
    "\n",
    "        # Beam, dictionary, with elements as list. Each element of list\n",
    "        # containing index of the selected output and the corresponding\n",
    "        # probability.\n",
    "        batch_size = data.size()[0]\n",
    "        h = Variable(torch.zeros(1, batch_size, self.hd_sz))\n",
    "        # Last beams' data\n",
    "        B = {0: {\"input\": input_op, \"h\": h}, 1: None}\n",
    "        next_B = {}\n",
    "        x_f = self.encoder(data)\n",
    "        x_f = x_f.view(1, batch_size, self.in_sz)\n",
    "        # List to store the probs of last time step\n",
    "        prev_output_prob = [\n",
    "            Variable(torch.ones(batch_size, self.input_op_sz))\n",
    "        ]\n",
    "        all_beams = []\n",
    "        all_inputs = []\n",
    "        for timestep in range(0, max_time):\n",
    "            outputs = []\n",
    "            for b in range(w):\n",
    "                if not B[b]:\n",
    "                    break\n",
    "                input_op = B[b][\"input\"]\n",
    "\n",
    "                h = B[b][\"h\"]\n",
    "                print(input_op.shape)\n",
    "                input_op_rnn = input_op[:,0,:].view(1, batch_size,\n",
    "                                                 self.input_op_sz)\n",
    "                input = torch.cat((x_f, input_op_rnn), 2)\n",
    "                out, h = self.rnn(input, h)\n",
    "                hd = self.relu(self.dense_fc_1(self.drop(out[0])))\n",
    "                dense_output = self.dense_output(self.drop(hd))\n",
    "                output = self.logsoftmax(dense_output)\n",
    "                # Element wise multiply by previous probabs\n",
    "                output = torch.nn.Softmax(1)(output)\n",
    "\n",
    "                output = output * prev_output_prob[b]\n",
    "                outputs.append(output)\n",
    "                next_B[b] = {}\n",
    "                next_B[b][\"h\"] = h\n",
    "            if len(outputs) == 1:\n",
    "                outputs = outputs[0]\n",
    "            else:\n",
    "                outputs = torch.cat(outputs, 1)\n",
    "\n",
    "            next_beams_index = torch.topk(outputs, w, 1, sorted=True)[1]\n",
    "            next_beams_prob = torch.topk(outputs, w, 1, sorted=True)[0]\n",
    "            # print (next_beams_prob)\n",
    "            current_beams = {\n",
    "                \"parent\":\n",
    "                next_beams_index.data.cpu().numpy() // (self.input_op_sz),\n",
    "                \"index\": next_beams_index % (self.input_op_sz)\n",
    "            }\n",
    "            # print (next_beams_index % (self.num_draws))\n",
    "            next_beams_index %= (self.input_op_sz)\n",
    "            all_beams.append(current_beams)\n",
    "\n",
    "            # Update previous output probabilities\n",
    "            temp = Variable(torch.zeros(batch_size, 1))\n",
    "            prev_output_prob = []\n",
    "            for i in range(w):\n",
    "                for index in range(batch_size):\n",
    "                    temp[index, 0] = next_beams_prob[index, i]\n",
    "                prev_output_prob.append(temp.repeat(1, self.input_op_sz))\n",
    "            # hidden state for next step\n",
    "            B = {}\n",
    "            for i in range(w):\n",
    "                B[i] = {}\n",
    "                temp = Variable(torch.zeros(h.size()))\n",
    "                for j in range(batch_size):\n",
    "                    temp[0, j, :] = next_B[current_beams[\"parent\"][j, i]][\"h\"][\n",
    "                        0, j, :]\n",
    "                B[i][\"h\"] = temp\n",
    "\n",
    "            # one_hot for input to the next step\n",
    "            for i in range(w):\n",
    "                arr = Variable(\n",
    "                    torch.zeros(batch_size, self.input_op_sz).scatter_(\n",
    "                        1, next_beams_index[:, i:i + 1].data.cpu(),\n",
    "                        1.0))\n",
    "                B[i][\"input\"] = arr.unsqueeze(1)\n",
    "            all_inputs.append(B)\n",
    "\n",
    "        return all_beams, next_beams_prob, all_inputs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 4, 7])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = torch.randn((4,8, 3, 256, 256)) #L, B, C, H, W\n",
    "input_op_idx = torch.randint(0, 7, (8, 4, 1))\n",
    "input_op = torch.zeros((8, 4, 7))\n",
    "input_op = input_op.scatter_(2, input_op_idx, 1) #B, L, S\n",
    "input_op.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "program_len = 3\n",
    "x = [data, input_op, program_len]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Image2NodeNet(256, 512, 8, enc, num_layers=1, time_steps=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_tuple_to_list(string_tuple):\n",
    "    non_bracket = string_tuple[1:-1]\n",
    "    sequence = non_bracket.split(',')\n",
    "    return sequence\n",
    "\n",
    "def create_vocabulary(labels):\n",
    "    sequences = list(labels.values())\n",
    "    unique_symbols = sorted(list(set(sym for seq in sequences for sym in seq)))\n",
    "    return unique_symbols\n",
    "\n",
    "def map_sym2idx(sym, uniq):\n",
    "    return uniq.index(sym)\n",
    "\n",
    "def map_idx2sym(idx, uniq):\n",
    "    return uniq[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Table_1': ['<s>', '1', '3', '4', '5', '</s>'],\n",
       " 'Table_2': ['<s>', '2', '3', '4', '5', '</s>'],\n",
       " 'Table_3': ['<s>', '7', '3', '4', '5', '</s>'],\n",
       " 'Table_4': ['<s>', '8', '3', '4', '5', '</s>'],\n",
       " 'Table_5': ['<s>', '9', '3', '4', '5', '</s>'],\n",
       " 'Table_6': ['<s>', '10', '3', '4', '5', '</s>'],\n",
       " 'Table_7': ['<s>', '11', '3', '4', '6', '</s>'],\n",
       " 'Table_8': ['<s>', '12', '3', '4', '6', '</s>'],\n",
       " 'Table_9': ['<s>', '13', '3', '4', '6', '</s>'],\n",
       " 'Table_10': ['<s>', '14', '3', '4', '6', '</s>'],\n",
       " 'Table_11': ['<s>', '15', '3', '4', '6', '</s>'],\n",
       " 'Table_12': ['<s>', '16', '3', '4', '6', '</s>']}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('data/tables/Tables_new.txt', 'r') as label_file:\n",
    "    labels = {}\n",
    "    for line in label_file:\n",
    "        stripped_line = line.strip()\n",
    "        table, label = stripped_line.split(' ')\n",
    "        sequence = ['<s>'] + string_tuple_to_list(label) + ['</s>']\n",
    "        labels[table] = sequence\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1',\n",
       " '10',\n",
       " '11',\n",
       " '12',\n",
       " '13',\n",
       " '14',\n",
       " '15',\n",
       " '16',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '6',\n",
       " '7',\n",
       " '8',\n",
       " '9',\n",
       " '</s>',\n",
       " '<s>']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniq = create_vocabulary(labels)\n",
    "uniq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Table_1': [17, 0, 9, 10, 11, 16],\n",
       " 'Table_2': [17, 8, 9, 10, 11, 16],\n",
       " 'Table_3': [17, 13, 9, 10, 11, 16],\n",
       " 'Table_4': [17, 14, 9, 10, 11, 16],\n",
       " 'Table_5': [17, 15, 9, 10, 11, 16],\n",
       " 'Table_6': [17, 1, 9, 10, 11, 16],\n",
       " 'Table_7': [17, 2, 9, 10, 12, 16],\n",
       " 'Table_8': [17, 3, 9, 10, 12, 16],\n",
       " 'Table_9': [17, 4, 9, 10, 12, 16],\n",
       " 'Table_10': [17, 5, 9, 10, 12, 16],\n",
       " 'Table_11': [17, 6, 9, 10, 12, 16],\n",
       " 'Table_12': [17, 7, 9, 10, 12, 16]}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_idx = {}\n",
    "for key, val in labels.items():\n",
    "    labels_idx[key] = [map_sym2idx(sym, uniq) for sym in val]\n",
    "labels_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Table_1': ['<s>', '1', '3', '4', '5', '</s>'],\n",
       " 'Table_2': ['<s>', '2', '3', '4', '5', '</s>'],\n",
       " 'Table_3': ['<s>', '7', '3', '4', '5', '</s>'],\n",
       " 'Table_4': ['<s>', '8', '3', '4', '5', '</s>'],\n",
       " 'Table_5': ['<s>', '9', '3', '4', '5', '</s>'],\n",
       " 'Table_6': ['<s>', '10', '3', '4', '5', '</s>'],\n",
       " 'Table_7': ['<s>', '11', '3', '4', '6', '</s>'],\n",
       " 'Table_8': ['<s>', '12', '3', '4', '6', '</s>'],\n",
       " 'Table_9': ['<s>', '13', '3', '4', '6', '</s>'],\n",
       " 'Table_10': ['<s>', '14', '3', '4', '6', '</s>'],\n",
       " 'Table_11': ['<s>', '15', '3', '4', '6', '</s>'],\n",
       " 'Table_12': ['<s>', '16', '3', '4', '6', '</s>']}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_sym = {}\n",
    "for key, val in labels_idx.items():\n",
    "    labels_sym[key] = [map_idx2sym(idx, uniq) for idx in val]\n",
    "labels_sym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/complete_symbol_sequence.json', 'w') as com_sym_file:\n",
    "    json.dump(labels, com_sym_file)\n",
    "\n",
    "with open('data/complete_index_sequence.json', 'w') as com_idx_file:\n",
    "    json.dump(labels_idx, com_idx_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def train_valid_test_split(num_images, num_test, num_dev):\n",
    "    all_indices = np.arange(num_images)\n",
    "    total_set_aside = num_test + num_dev\n",
    "    set_aside_indices = []\n",
    "    for i in range(total_set_aside):\n",
    "        if i==0:\n",
    "            idx = i+1\n",
    "        else:\n",
    "            idx = set_aside_indices[-1] + 2\n",
    "        set_aside_indices.append(all_indices[idx])\n",
    "    \n",
    "    test_indices = random.sample(set_aside_indices, 2)\n",
    "    dev_indices = list(np.setdiff1d(set_aside_indices, test_indices))\n",
    "    \n",
    "    return test_indices, dev_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test_indices:  [1, 3]\n",
      "Dev_indices:  [5, 7]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_indices, dev_indices = train_valid_test_split(10, 2, 2)\n",
    "print('Test_indices: ', test_indices)\n",
    "print('Dev_indices: ', dev_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_dev_test_examples(path, test_indices, dev_indices):\n",
    "    examples = sorted(glob.glob(os.path.join(path, '*.png')))\n",
    "    test_examples = [ex for ex in examples if int(os.path.splitext(ex)[0][-1]) in test_indices]\n",
    "    dev_examples = [ex for ex in examples if int(os.path.splitext(ex)[0][-1]) in dev_indices]\n",
    "    train_examples = list(np.setdiff1d(examples, test_examples+dev_examples))\n",
    "    return test_examples, dev_examples, train_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./data/tables/Table_1/Table_1_Image_1.png', './data/tables/Table_1/Table_1_Image_3.png']\n",
      "['./data/tables/Table_1/Table_1_Image_5.png', './data/tables/Table_1/Table_1_Image_7.png']\n",
      "['./data/tables/Table_1/Table_1_Image_10.png', './data/tables/Table_1/Table_1_Image_2.png', './data/tables/Table_1/Table_1_Image_4.png', './data/tables/Table_1/Table_1_Image_6.png', './data/tables/Table_1/Table_1_Image_8.png', './data/tables/Table_1/Table_1_Image_9.png']\n"
     ]
    }
   ],
   "source": [
    "test_ex, dev_ex, examples = get_train_dev_test_examples('./data/tables/Table_1', test_indices, dev_indices)\n",
    "print(test_ex)\n",
    "print(dev_ex)\n",
    "print(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Table_3',\n",
       " 'Table_4',\n",
       " 'Table_11',\n",
       " 'Table_5',\n",
       " 'Table_2',\n",
       " 'Table_10',\n",
       " 'Table_12',\n",
       " 'Table_9',\n",
       " 'Table_7',\n",
       " 'Table_1',\n",
       " 'Table_6',\n",
       " 'Table_8']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_dir = './data/tables'\n",
    "table_folders = [folder for folder in os.listdir(root_dir) if not folder.endswith('.txt') and not folder.startswith('.')]\n",
    "table_folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = []\n",
    "test_set = []\n",
    "dev_set = []\n",
    "for folder in table_folders:\n",
    "    path = os.path.join(root_dir, folder)\n",
    "    test_indices, dev_indices = train_valid_test_split(10, 2, 2)\n",
    "    test_ex, dev_ex, train_ex = get_train_dev_test_examples(path, test_indices, dev_indices)\n",
    "    train_set += train_ex\n",
    "    test_set += test_ex\n",
    "    dev_set += dev_ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total train_examples:  72\n",
      "Total test_examples:  24\n",
      "Total dev_examples:  24\n"
     ]
    }
   ],
   "source": [
    "print('Total train_examples: ', len(train_set))\n",
    "print('Total test_examples: ', len(test_set))\n",
    "print('Total dev_examples: ', len(dev_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dump_json(filepath, ex):\n",
    "    with open(filepath, 'w') as file:\n",
    "        json.dump(ex, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_json('./data/train.json', train_set)\n",
    "dump_json('./data/test.json', test_set)\n",
    "dump_json('./data/dev.json', dev_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def load_json(json_path):\n",
    "    with open(json_path, 'r') as j:\n",
    "        content = json.load(j)\n",
    "    return content\n",
    "\n",
    "class Image2NodeDataset(Dataset):\n",
    "    def __init__(self, im_json, label_json):\n",
    "        self.images = load_json(im_json)\n",
    "        self.labels = load_json(label_json)\n",
    "        transform_list = [transforms.ToTensor(),\n",
    "                          transforms.Normalize((0.5,0.5, 0.5), (0.5,0.5, 0.5))]\n",
    "\n",
    "        self.transform = transforms.Compose(transform_list)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(self.images[idx]).convert('RGB')\n",
    "        image_256 = transforms.functional.resize(image, 256, transforms.InterpolationMode.BICUBIC)\n",
    "        image_t = self.transform(image_256)\n",
    "\n",
    "        #label\n",
    "        filename = os.path.split(self.images[idx])[1]\n",
    "        object_name = '_'.join(filename.split('_')[:2]) \n",
    "        sequence = torch.tensor(self.labels[object_name])\n",
    "        ip_op = sequence[:-1]\n",
    "        label = sequence[1:]\n",
    "        return {'image':image_t, 'inp_op':ip_op, 'label': label, 'program_len': len(sequence) - 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = Image2NodeDataset('./data/train.json', './data/complete_index_sequence.json')\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 256, 455])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = dataset[1]\n",
    "i['image'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(dataset, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 3, 256, 455])\n",
      "torch.Size([8, 5])\n",
      "torch.Size([8, 5])\n",
      "tensor([4, 4, 4, 4, 4, 4, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(loader))\n",
    "print(batch['image'].shape)\n",
    "print(batch['inp_op'].shape)\n",
    "print(batch['label'].shape)\n",
    "print(batch['program_len'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 8, 519])\n",
      "torch.Size([1, 8, 519])\n",
      "torch.Size([1, 8, 519])\n",
      "torch.Size([1, 8, 519])\n"
     ]
    }
   ],
   "source": [
    "op = model.beam_search([batch['image'], input_op], )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 5, 1])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image, input_op_idx, label, program_len = batch['image'], batch['inp_op'], batch['label'], batch['program_len']\n",
    "input_op_idx = input_op_idx.unsqueeze(2)\n",
    "input_op_idx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 5, 8])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_op = torch.zeros((input_op_idx.shape[0], input_op_idx.shape[1], 8))\n",
    "input_op = input_op.scatter_(2, input_op_idx, 1) #B, L, S\n",
    "input_op.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[7],\n",
       "        [0],\n",
       "        [2],\n",
       "        [3],\n",
       "        [4]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_op_idx[0,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_op[:,0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 5, 8])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_op.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 5, 8])\n",
      "torch.Size([8, 1, 8])\n",
      "torch.Size([8, 1, 8])\n",
      "torch.Size([8, 1, 8])\n",
      "torch.Size([8, 1, 8])\n",
      "torch.Size([8, 1, 8])\n",
      "torch.Size([8, 1, 8])\n",
      "torch.Size([8, 1, 8])\n",
      "torch.Size([8, 1, 8])\n",
      "torch.Size([8, 1, 8])\n",
      "torch.Size([8, 1, 8])\n",
      "torch.Size([8, 1, 8])\n",
      "torch.Size([8, 1, 8])\n"
     ]
    }
   ],
   "source": [
    "all_beams, next_beams_prob, all_inputs = model.beam_search([image, input_op], 3, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor([1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       "indices=tensor([7, 7, 7, 7, 7, 7, 7, 7]))"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(input_op[:,0,:], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beams_parser(all_beams, batch_size, beam_width=5):\n",
    "    # all_beams = [all_beams[k].data.numpy() for k in all_beams.keys()]\n",
    "    all_expression = {}\n",
    "    W = beam_width\n",
    "    T = len(all_beams)\n",
    "    for batch in range(batch_size):\n",
    "        all_expression[batch] = []\n",
    "        for w in range(W):\n",
    "            temp = []\n",
    "            parent = w\n",
    "            for t in range(T - 1, -1, -1):\n",
    "                temp.append(all_beams[t][\"index\"][batch, parent].data.cpu()\n",
    "                            .numpy())\n",
    "                parent = all_beams[t][\"parent\"][batch, parent]\n",
    "            temp = temp[::-1]\n",
    "            all_expression[batch].append(np.array(temp))\n",
    "        all_expression[batch] = np.squeeze(np.array(all_expression[batch]))\n",
    "    return all_expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(2)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_beams[4][\"index\"][0, 0].data.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = beams_parser(all_beams, 8, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: array([[5, 5, 4, 4, 5],\n",
       "        [5, 5, 4, 4, 2],\n",
       "        [2, 4, 1, 4, 5]]),\n",
       " 1: array([[4, 3, 5, 5, 4],\n",
       "        [4, 3, 5, 5, 1],\n",
       "        [4, 3, 5, 5, 2]]),\n",
       " 2: array([[4, 2, 5, 2, 1],\n",
       "        [4, 2, 5, 1, 4],\n",
       "        [4, 2, 5, 1, 5]]),\n",
       " 3: array([[0, 1, 4, 5, 4],\n",
       "        [0, 1, 4, 5, 2],\n",
       "        [7, 5, 5, 1, 2]]),\n",
       " 4: array([[1, 2, 1, 4, 1],\n",
       "        [1, 2, 1, 5, 2],\n",
       "        [1, 2, 1, 5, 1]]),\n",
       " 5: array([[4, 4, 4, 1, 2],\n",
       "        [4, 4, 4, 1, 4],\n",
       "        [4, 4, 4, 1, 1]]),\n",
       " 6: array([[4, 1, 1, 2, 2],\n",
       "        [2, 2, 4, 4, 2],\n",
       "        [2, 2, 4, 4, 7]]),\n",
       " 7: array([[4, 2, 5, 2, 4],\n",
       "        [4, 2, 5, 2, 2],\n",
       "        [5, 2, 1, 4, 2]])}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'parent': array([[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]]),\n",
       "  'index': tensor([[4, 5, 2],\n",
       "          [4, 2, 1],\n",
       "          [4, 1, 2],\n",
       "          [7, 0, 4],\n",
       "          [1, 4, 7],\n",
       "          [4, 7, 1],\n",
       "          [2, 4, 6],\n",
       "          [4, 0, 5]])},\n",
       " {'parent': array([[0, 2, 1],\n",
       "         [0, 0, 1],\n",
       "         [0, 0, 0],\n",
       "         [1, 0, 2],\n",
       "         [0, 1, 0],\n",
       "         [0, 0, 1],\n",
       "         [0, 0, 1],\n",
       "         [0, 2, 1]]),\n",
       "  'index': tensor([[1, 4, 5],\n",
       "          [4, 3, 4],\n",
       "          [2, 5, 1],\n",
       "          [1, 5, 4],\n",
       "          [2, 1, 0],\n",
       "          [4, 0, 1],\n",
       "          [2, 4, 1],\n",
       "          [2, 2, 2]])},\n",
       " {'parent': array([[0, 2, 1],\n",
       "         [1, 0, 0],\n",
       "         [0, 1, 1],\n",
       "         [0, 1, 0],\n",
       "         [0, 0, 2],\n",
       "         [0, 1, 1],\n",
       "         [0, 0, 2],\n",
       "         [0, 1, 2]]),\n",
       "  'index': tensor([[4, 4, 1],\n",
       "          [5, 5, 1],\n",
       "          [5, 4, 2],\n",
       "          [4, 5, 2],\n",
       "          [1, 2, 5],\n",
       "          [4, 1, 7],\n",
       "          [2, 4, 1],\n",
       "          [5, 1, 2]])},\n",
       " {'parent': array([[1, 0, 2],\n",
       "         [0, 1, 0],\n",
       "         [0, 0, 0],\n",
       "         [1, 1, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 2, 1],\n",
       "         [1, 0, 2],\n",
       "         [0, 1, 0]]),\n",
       "  'index': tensor([[4, 4, 4],\n",
       "          [5, 2, 1],\n",
       "          [2, 5, 1],\n",
       "          [1, 2, 5],\n",
       "          [5, 1, 4],\n",
       "          [1, 4, 0],\n",
       "          [4, 2, 2],\n",
       "          [2, 4, 1]])},\n",
       " {'parent': array([[0, 0, 2],\n",
       "         [0, 0, 0],\n",
       "         [0, 2, 2],\n",
       "         [2, 2, 0],\n",
       "         [2, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [2, 0, 0],\n",
       "         [0, 0, 1]]),\n",
       "  'index': tensor([[5, 2, 5],\n",
       "          [4, 1, 2],\n",
       "          [1, 4, 5],\n",
       "          [4, 2, 2],\n",
       "          [1, 2, 1],\n",
       "          [2, 4, 1],\n",
       "          [2, 2, 7],\n",
       "          [4, 2, 2]])}]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_beams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from Dataset import Image2NodeDataset\n",
    "from models import Image2NodeNet, ResnetEncoder\n",
    "from utils import beams_parser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset = Image2NodeDataset('./data/test.json', './data/complete_index_sequence.json')\n",
    "len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(test_dataset, shuffle=False, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['epoch', 'model_state', 'encoder_state', 'best_val_loss'])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt = torch.load('./model/tables_12/best_model.pth', map_location=torch.device('cpu'))\n",
    "ckpt.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building resnet18 model (pretrained=False)!!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Image2NodeNet(\n",
       "  (encoder): ResnetEncoder(\n",
       "    (features): Sequential(\n",
       "      (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (4): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (5): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (6): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (7): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (8): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (rnn): GRU(530, 256)\n",
       "  (logsoftmax): LogSoftmax(dim=1)\n",
       "  (softmax): Softmax(dim=1)\n",
       "  (dense_fc_1): Linear(in_features=256, out_features=256, bias=True)\n",
       "  (dense_output): Linear(in_features=256, out_features=18, bias=True)\n",
       "  (drop): Dropout(p=0.5, inplace=False)\n",
       "  (sigmoid): Sigmoid()\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im_encoder = ResnetEncoder(arch_name='resnet18', in_channels=3, \n",
    "                           pretrained=False)\n",
    "im_encoder.load_state_dict(ckpt['encoder_state'])\n",
    "im_encoder.eval()\n",
    "image2node_net = Image2NodeNet(hd_sz=256, input_size=512, inp_op_sz=16+2,\n",
    "                             encoder=im_encoder)\n",
    "image2node_net.load_state_dict(ckpt['model_state'])\n",
    "image2node_net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1/24 [00:00<00:06,  3.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 5, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 3/24 [00:00<00:04,  5.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 5, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 5, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 5/24 [00:00<00:03,  5.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 5, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 5, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 7/24 [00:01<00:02,  5.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 5, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 5, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 8/24 [00:01<00:02,  6.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 5, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 9/24 [00:01<00:02,  5.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 5, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 11/24 [00:02<00:02,  4.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 5, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 5, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 13/24 [00:02<00:02,  5.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 5, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 5, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▎   | 15/24 [00:02<00:01,  5.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 5, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 5, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 16/24 [00:03<00:01,  5.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 5, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 5, 18])\n",
      "torch.Size([1, 1, 18])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 18/24 [00:03<00:01,  5.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 5, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 20/24 [00:03<00:00,  5.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 5, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 5, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 22/24 [00:04<00:00,  5.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 5, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 5, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:04<00:00,  5.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 5, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 5, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n",
      "torch.Size([1, 1, 18])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "expressions = []\n",
    "for batch in tqdm(loader):\n",
    "        image = batch['image']\n",
    "        input_op_idx, label, program_lens = batch['inp_op'], batch['label'], batch['program_len']\n",
    "        # Reshaping and getting one hot encoding of input operations\n",
    "        input_op = torch.zeros((input_op_idx.shape[0], input_op_idx.shape[1], 16+2))\n",
    "        input_op = input_op.scatter_(2, input_op_idx.unsqueeze(2), 1)\n",
    "        all_beams, next_beams_prob, all_inputs = image2node_net.beam_search([image, input_op], 3, 5)\n",
    "        expression = beams_parser(all_beams, 1, 1)\n",
    "        expressions.append(expression)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{0: array([ 2,  9, 10, 12, 16])},\n",
       " {0: array([ 2,  9, 10, 12, 16])},\n",
       " {0: array([ 1,  9, 10, 11, 16])},\n",
       " {0: array([14,  9, 10, 11, 16])},\n",
       " {0: array([ 2,  9, 10, 12, 16])},\n",
       " {0: array([ 6,  9, 10, 12, 16])},\n",
       " {0: array([ 1,  9, 10, 11, 16])},\n",
       " {0: array([ 2,  9, 10, 12, 16])},\n",
       " {0: array([ 2,  9, 10, 12, 16])},\n",
       " {0: array([ 1,  9, 10, 12, 16])},\n",
       " {0: array([ 3,  9, 10, 12, 16])},\n",
       " {0: array([ 7,  9, 10, 12, 16])},\n",
       " {0: array([ 2,  9, 10, 12, 16])},\n",
       " {0: array([ 7,  9, 10, 12, 16])},\n",
       " {0: array([ 2,  9, 10, 12, 16])},\n",
       " {0: array([ 6,  9, 10, 12, 16])},\n",
       " {0: array([ 2,  9, 10, 12, 16])},\n",
       " {0: array([ 6,  9, 10, 12, 16])},\n",
       " {0: array([ 6,  9, 10, 12, 16])},\n",
       " {0: array([ 2,  9, 10, 12, 16])},\n",
       " {0: array([ 6,  9, 10, 12, 16])},\n",
       " {0: array([ 1,  9, 10, 11, 16])},\n",
       " {0: array([ 3,  9, 10, 12, 16])},\n",
       " {0: array([ 3,  9, 10, 12, 16])}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['11', '3', '4', '6', '</s>'],\n",
       " ['11', '3', '4', '6', '</s>'],\n",
       " ['10', '3', '4', '5', '</s>'],\n",
       " ['8', '3', '4', '5', '</s>'],\n",
       " ['11', '3', '4', '6', '</s>'],\n",
       " ['15', '3', '4', '6', '</s>'],\n",
       " ['10', '3', '4', '5', '</s>'],\n",
       " ['11', '3', '4', '6', '</s>'],\n",
       " ['11', '3', '4', '6', '</s>'],\n",
       " ['10', '3', '4', '6', '</s>'],\n",
       " ['12', '3', '4', '6', '</s>'],\n",
       " ['16', '3', '4', '6', '</s>'],\n",
       " ['11', '3', '4', '6', '</s>'],\n",
       " ['16', '3', '4', '6', '</s>'],\n",
       " ['11', '3', '4', '6', '</s>'],\n",
       " ['15', '3', '4', '6', '</s>'],\n",
       " ['11', '3', '4', '6', '</s>'],\n",
       " ['15', '3', '4', '6', '</s>'],\n",
       " ['15', '3', '4', '6', '</s>'],\n",
       " ['11', '3', '4', '6', '</s>'],\n",
       " ['15', '3', '4', '6', '</s>'],\n",
       " ['10', '3', '4', '5', '</s>'],\n",
       " ['12', '3', '4', '6', '</s>'],\n",
       " ['12', '3', '4', '6', '</s>']]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_idx = []\n",
    "for val in expressions:\n",
    "    labels_idx.append([map_idx2sym(sym, uniq) for sym in val[0]])\n",
    "labels_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['12', '3', '4', '6', '</s>'], ['12', '3', '4', '6', '</s>']]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 22\n",
    "labels_idx[i:i+2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c6e4e9f98eb68ad3b7c296f83d20e6de614cb42e90992a65aa266555a3137d0d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
